{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c55babbd-d4ef-4d2a-9138-a7b82e23a246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total log count: 6210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained log count: 2254\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 처리 시나리오의 경우 (1)\n",
    "# 이를 실행하면 Data 추출기에서 획득한 Parquet 파일을 읽어들여 사용할 수 있는 형태로 변환한다.\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "case_name = \"normal_6\"\n",
    "uuid_cols_name = [\"job_id\", \"task_id\"]\n",
    "\n",
    "def conv_uuid(target):\n",
    "    global uuid_cols_name\n",
    "    df = pd.read_parquet(f'{target}.parquet', engine='pyarrow')\n",
    "    for col in df.columns:\n",
    "        if col in uuid_cols_name:\n",
    "            df[col] = df[col].apply(lambda x: uuid.UUID(bytes=x))\n",
    "    return df\n",
    "\n",
    "def unlimit_print():\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "def limit_print():\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "\n",
    "unlimit_print()\n",
    "\n",
    "log_df = conv_uuid(f\"./{case_name}/logs\")\n",
    "task_df = conv_uuid(f\"./{case_name}/tasks\")\n",
    "#display(log_df.head(1))\n",
    "print(f\"total log count: {len(log_df)}\")\n",
    "log_df = log_df[\n",
    "    (log_df[\"job_id\"] != uuid.UUID(\"00000000-0000-0000-0000-000000000000\")) & \n",
    "    (log_df[\"dst_port\"] != 53)]\n",
    "tl_df = pd.merge(log_df, task_df, on=['job_id','task_id'], how='inner')[['task_id','src_endpoint','dst_endpoint','range_begin','range_end','src_ip','src_port','dst_ip','dst_port','packet_size']]\n",
    "display(len(tl_df), len(task_df), len(log_df))\n",
    "#display(task_df)\n",
    "print(f\"remained log count: {len(log_df)}\")\n",
    "\n",
    "limit_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d724eb6-6025-483f-b368-25dfa2207279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== \n",
      "Anomaly Occurred:\n",
      "task_id                      2126eba5-869d-406c-b97e-2973d8d4cd6b\n",
      "src_endpoint                   minio.minio-s.svc.cluster.local:80\n",
      "dst_endpoint    ec2-15-164-214-122.ap-northeast-2.compute.amaz...\n",
      "range_begin                                                  4500\n",
      "range_end                                                    4600\n",
      "src_ip                                                 10.2.2.139\n",
      "src_port                                                     8080\n",
      "dst_ip                                                 10.2.1.161\n",
      "dst_port                                                    48848\n",
      "packet_size                                                    66\n",
      "Name: 768, dtype: object\n",
      "================================================== \n",
      "Anomaly Occurred:\n",
      "task_id                      7fbb96d5-1aeb-41cd-881a-914f071775d9\n",
      "src_endpoint                   minio.minio-s.svc.cluster.local:80\n",
      "dst_endpoint    ec2-15-164-214-122.ap-northeast-2.compute.amaz...\n",
      "range_begin                                                  6100\n",
      "range_end                                                    6200\n",
      "src_ip                                                 10.2.1.248\n",
      "src_port                                                     8080\n",
      "dst_ip                                                 10.2.1.161\n",
      "dst_port                                                    40370\n",
      "packet_size                                                    66\n",
      "Name: 1177, dtype: object\n",
      "================================================== \n",
      "Anomaly Occurred:\n",
      "task_id                      7fbb96d5-1aeb-41cd-881a-914f071775d9\n",
      "src_endpoint                   minio.minio-s.svc.cluster.local:80\n",
      "dst_endpoint    ec2-15-164-214-122.ap-northeast-2.compute.amaz...\n",
      "range_begin                                                  6100\n",
      "range_end                                                    6200\n",
      "src_ip                                                 10.2.1.248\n",
      "src_port                                                     8080\n",
      "dst_ip                                                 10.2.1.161\n",
      "dst_port                                                    40382\n",
      "packet_size                                                    74\n",
      "Name: 1178, dtype: object\n",
      "================================================== \n",
      "Anomaly Occurred:\n",
      "task_id                      7fbb96d5-1aeb-41cd-881a-914f071775d9\n",
      "src_endpoint                   minio.minio-s.svc.cluster.local:80\n",
      "dst_endpoint    ec2-15-164-214-122.ap-northeast-2.compute.amaz...\n",
      "range_begin                                                  6100\n",
      "range_end                                                    6200\n",
      "src_ip                                                 10.2.1.248\n",
      "src_port                                                     8080\n",
      "dst_ip                                                 10.2.1.161\n",
      "dst_port                                                    40382\n",
      "packet_size                                                    66\n",
      "Name: 1179, dtype: object\n",
      "skipped_cnt: 1042 / meaningful cnt: 1212 /  correct_cnt: 1208 / tot_cnt: 2254\n",
      "Accuracy:  99.66996699669967 %\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 처리 시나리오의 경우 (2)\n",
    "# (1)을 먼저 실행한 뒤에 실행할 것.\n",
    "# Data 추출기에서 획득한 json 양식 Bucket 데이터를 Parquet으로 가공된 트래픽 로그와 비교하여, 두 정보가 불일치하는 점이 존재하는지 파악한다.\n",
    "# 주의: 불일치 로그로 Driver-Executor 간 통신이 걸리곤 하는데, 이는 동작 최적화가 이루어지지 않아 Task 맥락 갱신에 딜레이가 걸려 일어난 것. 하단의 주석을 참고한다.\n",
    "import re\n",
    "import json\n",
    "\n",
    "def normalize_range(port_range_str):\n",
    "    start, end = map(int, port_range_str.split('_to_'))\n",
    "    return start, end\n",
    "\n",
    "source = \"10.2.0.11\"\n",
    "normal_dst = \"54.180.115.209\"\n",
    "mal_dst = \"15.164.214.122\"\n",
    "\n",
    "normal_data = {}\n",
    "mal_data = {}\n",
    "with open(f\"./{case_name}/normal-bucket.json\", \"r\", encoding='utf-8') as f:\n",
    "    normal_obj = json.load(f)[\"metadata\"]\n",
    "    for obj in normal_obj:\n",
    "        match = re.match(r\"^([0-9a-f\\-]{36})\\.([0-9a-f\\-]{36})\\.((?:\\d{1,3}\\.){3}\\d{1,3})\\.(\\d+_to_\\d+)\\.gzip$\", obj[\"object_name\"])\n",
    "        job_id, task_id, ip_addr, data_range = match.groups()\n",
    "        if match:\n",
    "            data_range = normalize_range(data_range)\n",
    "            normal_data[task_id] = {\"ip\": ip_addr, \"data_begin\": data_range[0], \"data_end\": data_range[1]}\n",
    "with open(f\"./{case_name}/malicious-bucket.json\", \"r\", encoding='utf-8') as f:\n",
    "    mal_obj = json.load(f)[\"metadata\"]\n",
    "    for obj in mal_obj:\n",
    "        match = re.match(r\"^([0-9a-f\\-]{36})\\.([0-9a-f\\-]{36})\\.((?:\\d{1,3}\\.){3}\\d{1,3})\\.(\\d+_to_\\d+)\\.gzip$\", obj[\"object_name\"])\n",
    "        job_id, task_id, ip_addr, data_range = match.groups()\n",
    "        if match:\n",
    "            data_range = normalize_range(data_range)\n",
    "            mal_data[task_id] = {\"ip\": ip_addr, \"data_begin\": data_range[0], \"data_end\": data_range[1]}\n",
    "\n",
    "correct_cnt = 0\n",
    "tot_cnt = len(tl_df)\n",
    "skipped_cnt = 0\n",
    "res = {}\n",
    "for _, log in tl_df.iterrows():\n",
    "    # 관심 없음.\n",
    "    if log[\"dst_ip\"] == source:\n",
    "        #tot_cnt -= 1\n",
    "        skipped_cnt += 1\n",
    "        continue\n",
    "    \n",
    "    if log[\"dst_ip\"] == normal_dst:\n",
    "        res = normal_data\n",
    "    elif log[\"dst_ip\"] == mal_dst:\n",
    "        res = mal_data\n",
    "    else:\n",
    "        print(\"=\" * 50, \"\\nAnomaly Occurred:\",)\n",
    "        print(log)\n",
    "        continue\n",
    "\n",
    "    task_id = str(log[\"task_id\"])\n",
    "    if log[\"src_ip\"] == res[task_id][\"ip\"] \\\n",
    "        and int(log[\"range_begin\"]) == res[task_id][\"data_begin\"] \\\n",
    "        and int(log[\"range_end\"]) == res[task_id][\"data_end\"]:\n",
    "        correct_cnt += 1\n",
    "        continue\n",
    "    \n",
    "    print(\"Unmatch Log Exists: \", log, \"\\n\\twith: \", res[task_id])\n",
    "# 일부 Miss가 존재하는데, 이건 RPC Response 과정에서 Task 맥락이 살짝 늦게 반영되서 발생한 일.\n",
    "# 원래는 해당 로그의 Task ID가 0이어야 함. Watcher에서 반영이 살짝 늦어져 Task와 관련된 트래픽으로 분류된 것. Source Port가 RPC Serving Port인 점에서 인지 가능.\n",
    "print(f\"skipped_cnt: {skipped_cnt} / meaningful cnt: {tot_cnt - skipped_cnt} /  correct_cnt: {correct_cnt} / tot_cnt: {tot_cnt}\")\n",
    "print(\"Accuracy: \", (correct_cnt / (tot_cnt - skipped_cnt)) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09b86065-8fa7-44b0-aeff-cd9206a59bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: anomaly_2 ==================\n",
      "total log count: 556453\n",
      "remained log count: 393057\n",
      "0\n",
      "Current: anomaly_3 ==================\n",
      "total log count: 536163\n",
      "remained log count: 372727\n",
      "0\n",
      "Current: anomaly_4 ==================\n",
      "total log count: 523746\n",
      "remained log count: 360324\n",
      "0\n",
      "Current: anomaly_5 ==================\n",
      "total log count: 518144\n",
      "remained log count: 354812\n",
      "0\n",
      "Current: anomaly_6 ==================\n",
      "total log count: 529131\n",
      "remained log count: 365733\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 이미지 처리 시나리오에서의 검증\n",
    "# 악성 Destination(이하 A), 정상 Destination(이하 N)이 존재한다고 가정하고, 확률적으로 악성 행위가 발생한다고 가정했음.\n",
    "# 악성 행위 및 정상 행위 여부인지를 먼저 확인하고,, 두 경우에서 반드시 일어나야 할 일이 일어났는지 확인한다.\n",
    "# 정상 행위의 경우, N에서 Task와 연관된 데이터가 존재해야 하며, A에 존재하지 않아야 한다. 또한, 트래픽 로그에 N에 접근한 로그는 반드시 있고, A에 접근한 로그는 반드시 없어야 한다.\n",
    "# 악성 행위의 경우, N과 A 모두 Task와 연관된 데이터가 존재해야 하며, 트래픽 로그에서도 N과 A에 모두 접근한 로그가 반드시 존재해야 한다.\n",
    "# 자세한 실험 설계는 정보과학회 논문을 참고한다.\n",
    "\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "base_name = \"anomaly\"\n",
    "source = \"10.2.0.11\"\n",
    "normal_dst = \"54.180.115.209\"\n",
    "mal_dst = \"15.164.214.122\"\n",
    "uuid_cols_name = [\"job_id\", \"task_id\"]\n",
    "\n",
    "\n",
    "def conv_uuid(target):\n",
    "    global uuid_cols_name\n",
    "    df = pd.read_parquet(f'{target}.parquet', engine='pyarrow')\n",
    "    for col in df.columns:\n",
    "        if col in uuid_cols_name:\n",
    "            df[col] = df[col].apply(lambda x: uuid.UUID(bytes=x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_range(port_range_str):\n",
    "    start, end = map(int, port_range_str.split('_to_'))\n",
    "    return start, end\n",
    "\n",
    "def test(case_name):\n",
    "    log_df = conv_uuid(f\"./{case_name}/logs\")\n",
    "    task_df = conv_uuid(f\"./{case_name}/tasks\")\n",
    "    #display(log_df.head(1))\n",
    "    print(f\"total log count: {len(log_df)}\")\n",
    "    log_df = log_df[\n",
    "        (log_df[\"job_id\"] != uuid.UUID(\"00000000-0000-0000-0000-000000000000\")) & \n",
    "        (log_df[\"dst_port\"] != 53) &\n",
    "        (log_df[\"src_port\"] != 8080)]\n",
    "    #display(task_df)\n",
    "    print(f\"remained log count: {len(log_df)}\")\n",
    "    \n",
    "    \n",
    "    normal_data = {}\n",
    "    mal_data = {}\n",
    "    with open(f\"./{case_name}/normal-bucket.json\", \"r\", encoding='utf-8') as f:\n",
    "        normal_obj = json.load(f)[\"metadata\"]\n",
    "        for obj in normal_obj:\n",
    "            match = re.match(r\"^([0-9a-f\\-]{36})\\.([0-9a-f\\-]{36})\\.((?:\\d{1,3}\\.){3}\\d{1,3})\\.(\\d+_to_\\d+)\\.gzip$\", obj[\"object_name\"])\n",
    "            job_id, task_id, ip_addr, data_range = match.groups()\n",
    "            if match:\n",
    "                data_range = normalize_range(data_range)\n",
    "                normal_data[task_id] = {\"ip\": ip_addr, \"data_begin\": data_range[0], \"data_end\": data_range[1]}\n",
    "    with open(f\"./{case_name}/malicious-bucket.json\", \"r\", encoding='utf-8') as f:\n",
    "        mal_obj = json.load(f)[\"metadata\"]\n",
    "        for obj in mal_obj:\n",
    "            match = re.match(r\"^([0-9a-f\\-]{36})\\.([0-9a-f\\-]{36})\\.((?:\\d{1,3}\\.){3}\\d{1,3})\\.(\\d+_to_\\d+)\\.gzip$\", obj[\"object_name\"])\n",
    "            job_id, task_id, ip_addr, data_range = match.groups()\n",
    "            if match:\n",
    "                data_range = normalize_range(data_range)\n",
    "                mal_data[task_id] = {\"ip\": ip_addr, \"data_begin\": data_range[0], \"data_end\": data_range[1]}\n",
    "    \n",
    "    \n",
    "    tasks = {}\n",
    "    \n",
    "    for _, log in log_df.iterrows():\n",
    "        # 관심 없음.\n",
    "        if log[\"task_id\"] not in tasks.keys():\n",
    "            tasks[log[\"task_id\"]] = {\"normal\" : False, \"anomaly\": False}\n",
    "        if log[\"dst_ip\"] == normal_dst:\n",
    "            tasks[log[\"task_id\"]][\"normal\"] = True\n",
    "        elif log[\"dst_ip\"] == mal_dst:\n",
    "            tasks[log[\"task_id\"]][\"anomaly\"] = True\n",
    "    \n",
    "    err_cnt = 0\n",
    "    for _, task_info in task_df.iterrows():\n",
    "        is_anomaly = bool(task_info[\"run_as_evil\"])\n",
    "        if not tasks[task_info[\"task_id\"]][\"normal\"]:\n",
    "            print(\"(general_log) Error on\", task_info[\"task_id\"])\n",
    "            err_cnt += 1\n",
    "            continue\n",
    "        if str(task_info[\"task_id\"]) not in normal_data.keys():\n",
    "            print(\"(general_dst) Error on\", task_info[\"task_id\"])\n",
    "            err_cnt += 1\n",
    "            continue\n",
    "            \n",
    "        if is_anomaly:\n",
    "            if not tasks[task_info[\"task_id\"]][\"anomaly\"]:\n",
    "                print(\"(anomaly_log) Error on\", task_info[\"task_id\"])\n",
    "                err_cnt += 1\n",
    "                continue\n",
    "            if str(task_info[\"task_id\"]) not in mal_data.keys():\n",
    "                print(\"(anomaly_dst) Error on\", task_info[\"task_id\"])\n",
    "                err_cnt += 1\n",
    "                continue\n",
    "        else:\n",
    "            if tasks[task_info[\"task_id\"]][\"anomaly\"]:\n",
    "                print(\"(normal_log) Error on\", task_info[\"task_id\"])\n",
    "                err_cnt += 1\n",
    "                continue\n",
    "            if str(task_info[\"task_id\"]) in mal_data.keys():\n",
    "                print(\"(normal_dst) Error on\", task_info[\"task_id\"])\n",
    "                err_cnt += 1\n",
    "                continue\n",
    "    print(err_cnt)\n",
    "\n",
    "for cname in [f\"{base_name}_{i}\" for i in range(2,7)]:\n",
    "    print(f\"Current: {cname} ==================\")\n",
    "    test(cname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - chroma",
   "language": "python",
   "name": "chroma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
